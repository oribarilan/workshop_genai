{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use create a bot with strucutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same setup\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "assert key, \"Please set the AZURE_OPENAI_API_KEY environment variable\"\n",
    "assert endpoint, \"Please set the AZURE_OPENAI_ENDPOINT environment variable\"\n",
    "assert deployment_name, \"Please set the DEPLOYMENT_NAME environment variable\"\n",
    "assert api_version, \"Please set the AZURE_OPENAI_API_VERSION environment variable\"\n",
    "\n",
    "SYS_MSG = \"You are a synonym and antonym bot. Given a <word> from the user, you will provide synonyms and antonyms for it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=api_version,  # type: ignore\n",
    "    azure_deployment=deployment_name,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", SYS_MSG), (\"human\", \"<word>{word}</word>\")]\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Synonyms for \"excited\":\\n- Thrilled\\n- Enthused\\n- Eager\\n- Animated\\n- Elated\\n\\nAntonyms for \"excited\":\\n- Calm\\n- Bored\\n- Uninterested\\n- Disinterested\\n- Indifferent', response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 47, 'total_tokens': 100}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-b912717d-460d-45c4-bff1-2fc5936cc06a-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Synonyms for \"excited\":\\n1. Thrilled\\n2. Enthusiastic\\n3. Eager\\n4. Animated\\n5. Ecstatic\\n6. Jubilant\\n7. Elated\\n8. Overjoyed\\n9. Delighted\\n10. Pumped\\n\\nAntonyms for \"excited\":\\n1. Calm\\n2. Composed\\n3. Cool\\n4. Collected\\n5. Serene\\n6. Relaxed\\n7. Unexcited\\n8. Indifferent\\n9. Apathetic\\n10. Bored'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is difficult to work with, since it is an AI Message. Let's get to know output parsers that make our life easier.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILURE! Why?\n",
      "Invalid json output: Synonyms for \"excited\" include thrilled, ecstatic, elated, enthusiastic, eager, and exhilarated. \n",
      "\n",
      "Antonyms for \"excited\" include calm, composed, indifferent, uninterested, and apathetic.\n"
     ]
    }
   ],
   "source": [
    "# nice! but for building nice apps, we will need some structure\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "try:\n",
    "    chain.invoke({\"word\": \"excited\"})\n",
    "except Exception as e:  # noqa: E722 (we know this is bad! :D)\n",
    "    print(\"FAILURE! Why?\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'excited',\n",
       " 'synonyms': ['thrilled', 'enthusiastic', 'eager', 'elated', 'animated'],\n",
       " 'antonyms': ['calm', 'unenthusiastic', 'indifferent', 'apathetic', 'bored']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our model output is not json formatter. let's adjust the prmopt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_MSG + \"\\n. Make sure your output is a valid JSON structure.\"),\n",
    "        (\"human\", \"{word}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice! But, we can do better. OOP and all that.\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class SynonymAntonym(BaseModel):\n",
    "    word: str = Field(\n",
    "        description=\"The word for which synonyms and antonyms are provided\"\n",
    "    )\n",
    "    synonyms: List[str] = Field(\n",
    "        description=\"List of synonyms for the word, at least one synonym is required\"\n",
    "    )\n",
    "    antonyms: List[str] = Field(description=\"List of antonyms for the word, if any\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SynonymAntonym)\n",
    "\n",
    "SYS_MSG = \"You are a synonym and antonym bot. Given a <word> from the user, you will provide synonyms and antonyms for it.\"\n",
    "# note that we also inject the instructions, so this prompt template is more future proof\n",
    "prompt = PromptTemplate(\n",
    "    template=SYS_MSG + \"\\n{format_instructions}\\n{word}\\n\",\n",
    "    input_variables=[\"word\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"word\": {\"title\": \"Word\", \"description\": \"The word for which synonyms and antonyms are provided\", \"type\": \"string\"}, \"synonyms\": {\"title\": \"Synonyms\", \"description\": \"List of synonyms for the word, at least one synonym is required\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"antonyms\": {\"title\": \"Antonyms\", \"description\": \"List of antonyms for the word, if any\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"word\", \"synonyms\", \"antonyms\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynonymAntonym(word='excited', synonyms=['thrilled', 'enthusiastic', 'eager', 'animated', 'elated'], antonyms=['bored', 'indifferent', 'apathetic', 'unenthusiastic', 'calm'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms for \"excited\": thrilled, enthusiastic, elated, exhilarated, animated, pumped, ecstatic, eager, roused, stirred.\n",
      "\n",
      "Antonyms for \"excited\": calm, composed, indifferent, uninterested, unenthusiastic, bored, disinterested, apathetic, unexcited, subdued.\n",
      "fails as expected:  <class 'langchain_core.exceptions.OutputParserException'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "# now lets force the chain to output something that does not corresponding exactly to the Pydantic model\n",
    "# this can simulate a model failure to align with the format instructions\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=SYS_MSG + \"\\n{word}\\n\",\n",
    "    input_variables=[\"word\"],\n",
    ")\n",
    "\n",
    "\n",
    "# adjust the chain so that it prints the output of the llm before the parser\n",
    "def printer(t: AIMessage):\n",
    "    print(t.content)\n",
    "    return t\n",
    "\n",
    "\n",
    "printer_lambda = RunnableLambda(printer)\n",
    "chain = prompt | llm | printer_lambda | parser\n",
    "\n",
    "try:\n",
    "    chain.invoke({\"word\": \"excited\"})\n",
    "except Exception as e:\n",
    "    print(\"fails as expected: \", type(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynonymAntonym(word='excited', synonyms=['thrilled', 'exhilarated', 'enthusiastic', 'elated', 'eager'], antonyms=['calm', 'composed', 'indifferent', 'unenthusiastic', 'bored'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "# remember - the prompt has no format instructions!\n",
    "\n",
    "chain_w_fix = prompt | llm | fixing_parser\n",
    "\n",
    "chain_w_fix.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
