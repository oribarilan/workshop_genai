{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use create a bot with strucutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same setup\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "assert key, \"Please set the AZURE_OPENAI_API_KEY environment variable\"\n",
    "assert endpoint, \"Please set the AZURE_OPENAI_ENDPOINT environment variable\"\n",
    "assert deployment_name, \"Please set the DEPLOYMENT_NAME environment variable\"\n",
    "assert api_version, \"Please set the AZURE_OPENAI_API_VERSION environment variable\"\n",
    "\n",
    "SYS_MSG = \"You are a synonym and antonym bot. Given a word, you will provide synonyms and antonyms for it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=api_version,  # type: ignore\n",
    "    azure_deployment=deployment_name,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", SYS_MSG), (\"human\", \"{word}\")])\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Synonyms for \"excited\":\\n1. Thrilled\\n2. Enthusiastic\\n3. Eager\\n4. elated\\n5. pumped\\n6. animated\\n7. exhilarated\\n8. electrified\\n9. fired up\\n10. overjoyed\\n\\nAntonyms for \"excited\":\\n1. Calm\\n2. Relaxed\\n3. Uninterested\\n4. Bored\\n5. Indifferent\\n6. Apathetic\\n7. Cool\\n8. Composed\\n9. Laid-back\\n10. Serene', response_metadata={'token_usage': {'completion_tokens': 115, 'prompt_tokens': 36, 'total_tokens': 151}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-6da880c4-b09c-457f-9ffd-bbfc5826b46e-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Synonyms for \"excited\": thrilled, exhilarated, enthusiastic, elated, animated, ecstatic, eager, pumped, fired up, electrified\\n\\nAntonyms for \"excited\": bored, uninterested, disinterested, indifferent, apathetic, calm, composed, relaxed, unenthusiastic, blas√©'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is difficult to work with, since it is an AI Message. Let's get to know output parsers that make our life easier.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILURE! Why?\n",
      "Invalid json output: Synonyms for \"excited\":\n",
      "- Thrilled\n",
      "- Enthusiastic\n",
      "- Eager\n",
      "- Animated\n",
      "- Exhilarated\n",
      "\n",
      "Antonyms for \"excited\":\n",
      "- Calm\n",
      "- Relaxed\n",
      "- Composed\n",
      "- Unenthusiastic\n",
      "- Indifferent\n"
     ]
    }
   ],
   "source": [
    "# nice! but for building nice apps, we will need some structure\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "try:\n",
    "    chain.invoke({\"word\": \"excited\"})\n",
    "except Exception as e:  # noqa: E722 (we know this is bad! :D)\n",
    "    print(\"FAILURE! Why?\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'excited',\n",
       " 'synonyms': ['thrilled', 'enthusiastic', 'eager', 'animated', 'elated'],\n",
       " 'antonyms': ['calm',\n",
       "  'composed',\n",
       "  'indifferent',\n",
       "  'unenthusiastic',\n",
       "  'apathetic']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our model output is not json formatter. let's adjust the prmopt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_MSG + \"\\n. Make sure your output is a valid JSON structure.\"),\n",
    "        (\"human\", \"{word}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynonymAntonym(word='happy', synonyms=['joyful', 'delighted', 'content', 'pleased'], antonyms=['sad', 'unhappy', 'depressed', 'miserable'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice! But, we can do better. OOP and all that.\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class SynonymAntonym(BaseModel):\n",
    "    word: str = Field(\n",
    "        description=\"The word for which synonyms and antonyms are provided\"\n",
    "    )\n",
    "    synonyms: List[str] = Field(\n",
    "        description=\"List of synonyms for the word, at least one synonym is required\"\n",
    "    )\n",
    "    antonyms: List[str] = Field(description=\"List of antonyms for the word, if any\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SynonymAntonym)\n",
    "\n",
    "# note that we also inject the instructions, so this prompt template is more future proof\n",
    "prompt = PromptTemplate(\n",
    "    template=SYS_MSG + \"\\n{format_instructions}\",\n",
    "    input_variables=[\"word\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke(\n",
    "    {\"word\": \"excited\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
