{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use create a bot with strucutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same setup\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "assert key, \"Please set the AZURE_OPENAI_API_KEY environment variable\"\n",
    "assert endpoint, \"Please set the AZURE_OPENAI_ENDPOINT environment variable\"\n",
    "assert deployment_name, \"Please set the DEPLOYMENT_NAME environment variable\"\n",
    "assert api_version, \"Please set the AZURE_OPENAI_API_VERSION environment variable\"\n",
    "\n",
    "SYS_MSG = \"You are a synonym and antonym bot. Given a word, you will provide synonyms and antonyms for it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=api_version,  # type: ignore\n",
    "    azure_deployment=deployment_name,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", SYS_MSG), (\"human\", \"{word}\")])\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Synonyms for \"excited\":\\n1. thrilled\\n2. exhilarated\\n3. elated\\n4. enthusiastic\\n5. eager\\n6. pumped\\n7. animated\\n8. electrified\\n9. jubilant\\n10. ecstatic\\n\\nAntonyms for \"excited\":\\n1. bored\\n2. calm\\n3. indifferent\\n4. uninterested\\n5. apathetic\\n6. disinterested\\n7. relaxed\\n8. composed\\n9. tranquil\\n10. cool', response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 36, 'total_tokens': 138}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-1c12c759-4cf6-4a91-9b71-477f82ccec38-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Synonyms for \"excited\": thrilled, exhilarated, enthusiastic, elated, animated, ecstatic, eager, pumped, fired up, electrified\\n\\nAntonyms for \"excited\": bored, uninterested, disinterested, indifferent, apathetic, calm, composed, relaxed, unenthusiastic, blas√©'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is difficult to work with, since it is an AI Message. Let's get to know output parsers that make our life easier.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILURE! Why?\n"
     ]
    }
   ],
   "source": [
    "# nice! but for building nice apps, we will need some structure\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "try:\n",
    "    chain.invoke({\"word\": \"excited\"})\n",
    "except:  # noqa: E722 (we know this is bad! :D)\n",
    "    print(\"FAILURE! Why?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'excited',\n",
       " 'synonyms': ['thrilled', 'enthusiastic', 'eager', 'elated', 'animated'],\n",
       " 'antonyms': ['calm', 'indifferent', 'apathetic', 'unenthusiastic', 'bored']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our model output is not json formatter. let's adjust the prmopt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_MSG + \"\\n. Make sure your output is a valid JSON structure.\"),\n",
    "        (\"human\", \"{word}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynonymAntonym(word='happy', synonyms=['joyful', 'content', 'delighted', 'pleased', 'glad'], antonyms=['sad', 'unhappy', 'miserable', 'depressed'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice! But, we can do better. OOP and all that.\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class SynonymAntonym(BaseModel):\n",
    "    word: str = Field(\n",
    "        description=\"The word for which synonyms and antonyms are provided\"\n",
    "    )\n",
    "    synonyms: List[str] = Field(\n",
    "        description=\"List of synonyms for the word, at least one synonym is required\"\n",
    "    )\n",
    "    antonyms: List[str] = Field(description=\"List of antonyms for the word, if any\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SynonymAntonym)\n",
    "\n",
    "# note that we also inject the instructions, so this prompt template is more future proof\n",
    "prompt = PromptTemplate(\n",
    "    template=SYS_MSG + \"\\n{format_instructions}\",\n",
    "    input_variables=[\"word\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke(\n",
    "    {\"word\": \"excited\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
