{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use create a bot with strucutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same setup\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "assert key, \"Please set the AZURE_OPENAI_API_KEY environment variable\"\n",
    "assert endpoint, \"Please set the AZURE_OPENAI_ENDPOINT environment variable\"\n",
    "assert deployment_name, \"Please set the DEPLOYMENT_NAME environment variable\"\n",
    "assert api_version, \"Please set the AZURE_OPENAI_API_VERSION environment variable\"\n",
    "\n",
    "SYS_MSG = \"You are a synonym and antonym bot. Given a word, you will provide synonyms and antonyms for it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=api_version,  # type: ignore\n",
    "    azure_deployment=deployment_name,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", SYS_MSG), (\"human\", \"{word}\")])\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Synonyms for \"excited\" include:\\n1. Thrilled\\n2. Enthusiastic\\n3. Eager\\n4. Ecstatic\\n5. Elated\\n6. Animated\\n7. Pumped\\n8. Fired up\\n9. Overjoyed\\n10. Hyped\\n\\nAntonyms for \"excited\" include:\\n1. Calm\\n2. Relaxed\\n3. Composed\\n4. Uninterested\\n5. Indifferent\\n6. Bored\\n7. Apathetic\\n8. Disinterested\\n9. Unenthusiastic\\n10. Unexcited', response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 36, 'total_tokens': 160}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-e963e9b3-788c-4cc0-9999-c2efba7d1887-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Synonyms for \"excited\": thrilled, exhilarated, enthusiastic, elated, animated, ecstatic, eager, pumped, fired up, electrified\\n\\nAntonyms for \"excited\": bored, uninterested, disinterested, indifferent, apathetic, calm, composed, relaxed, unenthusiastic, blas√©'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is difficult to work with, since it is an AI Message. Let's get to know output parsers that make our life easier.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILURE! Why?\n"
     ]
    }
   ],
   "source": [
    "# nice! but for building nice apps, we will need some structure\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "try:\n",
    "    chain.invoke({\"word\": \"excited\"})\n",
    "except:  # noqa: E722 (we know this is bad! :D)\n",
    "    print(\"FAILURE! Why?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'excited',\n",
       " 'synonyms': ['thrilled', 'enthusiastic', 'eager', 'elated', 'animated'],\n",
       " 'antonyms': ['calm', 'indifferent', 'apathetic', 'unenthusiastic', 'bored']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our model output is not json formatter. let's adjust the prmopt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_MSG + \"\\n. Make sure your output is a valid JSON structure.\"),\n",
    "        (\"human\", \"{word}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "chain.invoke({\"word\": \"excited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynonymAntonym(word='happy', synonyms=['joyful', 'content', 'delighted', 'pleased', 'glad'], antonyms=['sad', 'unhappy', 'miserable', 'depressed'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice! But, we can do better. OOP and all that.\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class SynonymAntonym(BaseModel):\n",
    "    word: str = Field(\n",
    "        description=\"The word for which synonyms and antonyms are provided\"\n",
    "    )\n",
    "    synonyms: List[str] = Field(\n",
    "        description=\"List of synonyms for the word, at least one synonym is required\"\n",
    "    )\n",
    "    antonyms: List[str] = Field(description=\"List of antonyms for the word, if any\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SynonymAntonym)\n",
    "\n",
    "# note that we also inject the instructions, so this prompt template is more future proof\n",
    "prompt = PromptTemplate(\n",
    "    template=SYS_MSG + \"\\n{format_instructions}\",\n",
    "    input_variables=[\"word\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke(\n",
    "    {\"word\": \"excited\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Saving Private Ryan', 'Cast Away', 'The Green Mile', 'Apollo 13'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read more about output parsers here: https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/\n",
    "# specifically retry parser (not to be confused with output-fixing parser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
