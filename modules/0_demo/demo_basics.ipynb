{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start by loading the environment variables\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "assert key, \"Please set the AZURE_OPENAI_API_KEY environment variable\"\n",
    "assert endpoint, \"Please set the AZURE_OPENAI_ENDPOINT environment variable\"\n",
    "assert deployment_name, \"Please set the DEPLOYMENT_NAME environment variable\"\n",
    "assert api_version, \"Please set the AZURE_OPENAI_API_VERSION environment variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One interesting fact is that the world's oldest known recipe is for beer. It was written on a clay tablet in ancient Sumeria around 1800 BC. Cheers to our ancient beer-loving ancestors!\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Vanilla chat experience\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(api_key=key, api_version=api_version, azure_endpoint=endpoint)  # type: ignore (asserted already)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,  # type: ignore (asserted already)\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an interesting know-it-all person.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Tell me one interesting fact.\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Did you know that there is a species of jellyfish called Turritopsis dohrnii, also known as the \"immortal jellyfish\"? It has the remarkable ability to revert back to its juvenile form after reaching maturity, effectively restarting its life cycle. This process can occur repeatedly, potentially making it biologically immortal.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2: Introducing LangChain\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    api_version=api_version,  # type: ignore\n",
    "    azure_deployment=deployment_name,\n",
    ")\n",
    "\n",
    "\n",
    "sys_msg = SystemMessage(content=\"You are an interesting know-it-all person.\")\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Tell me one interesting fact\",\n",
    ")\n",
    "# introduce randomness in the response\n",
    "response = model.invoke([sys_msg, human_msg], temperature=0.9, top_p=0.9, frequency_penalty=0.5, presence_penalty=0.6)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log file contains a series of events that occurred within a system. Some anomalies can be observed from the log. \n",
      "\n",
      "First, there were multiple failed login attempts for the user456, followed by a successful login. This could indicate a potential security breach or unauthorized access. Additionally, there was an unauthorized access attempt detected, resulting in the blocking of the IP address 192.168.1.100.\n",
      "\n",
      "There were also several errors related to the payment process. A transaction failed initially but was retried and eventually succeeded. Furthermore, a fraudulent transaction was detected and flagged for review, indicating potential fraudulent activity.\n",
      "\n",
      "Server-related anomalies include server overload, unexpected server crashes, low disk space, and multiple server failures. These issues were addressed through server restart, disk cleanup, and server failover.\n",
      "\n",
      "Database anomalies include high memory usage, slow queries, data corruption, and high CPU usage. These issues were resolved through memory optimization, query optimization, data restoration, and CPU usage normalization.\n",
      "\n",
      "Lastly, there were security-related anomalies such as session expiration, suspicious activity from IP address 10.0.0.5, and a session hijacking attempt. These issues were addressed by re-login, monitoring the IP address, and terminating the user session.\n",
      "\n",
      "Overall, the log file highlights various anomalies, including potential security breaches, payment-related issues, server failures, database problems, and security threats. These anomalies should be investigated and addressed to ensure the system's stability, security, and performance.\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Log Analysis\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    api_version=api_version,  # type: ignore\n",
    "    azure_deployment=deployment_name,\n",
    ")\n",
    "\n",
    "log = Path(\"logs.log\").read_text()\n",
    "\n",
    "sys_msg = SystemMessage(content=\"You are an expert software engineer.\")\n",
    "human_msg = HumanMessage(\n",
    "    content=f\"Analyze the following log file and create a short paragraph-long summary of it, highlighting anomalies:\\n\\n<logs>\\n\\n{log}\\n\\n</logs>\",\n",
    ")\n",
    "# introduce randomness in the response\n",
    "response = model.invoke([sys_msg, human_msg], temperature=0.3)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
